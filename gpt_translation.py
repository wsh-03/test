# openai conda environment
# python 3.6.9
from openai import OpenAI
import os
from file_utility import FileProcessor

FileProcessor = FileProcessor()
def generate_prompt(path2file, error):
    bindgen_import = "use kernel::bindings::*"
    task = f"""
            You are a Rust system programming expert.
            Your task is to translate the Original C code to Rust code. You will be provided with information about the target machine and a C file from the Linux kernel source code.
            If compilation errors occur, you will be asked to fix them and correct the Rust code accordingly with given error message, otherwise provide the translated Rust code.
            Your translation must adhere to the following principles: 
            - Your translation must be functionally equivalent to the original C code
            - You must correctly use the foreign function interfaces generated by Bindgen, which are accessible through "{bindgen_import}".
            - Your translation must be safe Rust code.
            - Your translation must be free of comments.
            - Your translation should be free of compilation errors.
            - Your translation must be placed in the correct Rust file with the same base name as the original C file.
            - Return only the code in your reply.
            - Do not include any additional formatting, such as markdown code blocks
        """
        
    file_type = ".c"
    driver_name = "rtc"
    
    file_class = FileProcessor()
    file_result = file_class.get_file_info(path2file, file_type)
    if file_result is not None:
        file_content, file_name = file_result
        if file_content is not None and file_name is not None:
            print(f"Filename: {file_name}")
            print(f"Content:\n{file_content}")
    else:
        raise Exception("Error encountered during reading file content or retrieving filename.")  
      
    clean_code = file_class.remove_comments(file_content)
    
    message = f"""
            The Linux kernel runs on a Ubuntu x86-64 machine, where {file_name} is located under the {driver_name} directory.
            Original C file: "{clean_code}"
            Error message: "{error}"
            """
    return task, message

def gpt_translate(path2file, error):
    if error is None:
        task, message = generate_prompt(path2file, error)
        prompt = f"{task}\n{message}"
        
        model_type = "o3-mini" 
        
        key =  os.environ.get('OPENAI_API_KEY')
        if not key:
            raise ValueError("OPENAI_API_KEY is not set.")
    
        client = OpenAI(api_key = key)
        response = client.responses.create(
            model = model_type,
            input = [
                {
                    "role": "user", 
                    "content": prompt
                }
            ]
        )
        # Get the reply content
        reply_content = response.output_text
        return reply_content
    
    elif error is not None:
        task, message = generate_prompt(path2file, error)
        model_type = "gpt-4o" 
        key =  os.environ.get('OPENAI_API_KEY')
        if not key:
            raise ValueError("OPENAI_API_KEY is not set.")
        
        # Set the API key for OpenAI
        client = OpenAI(api_key = key)
        # Call the OpenAI API
        response  = client.responses.create(
            model = model_type,
            messages = [
                    {
                        "role": "system developer", 
                        "content": f"{task}"
                    },
                
                    {
                        "role": "user",
                         "content": f"{message}"
                    }
                        ])
        
        # Get the reply content
        reply_content = response.output_text    
        return reply_content
    
